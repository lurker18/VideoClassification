{
  "best_metric": 0.9307165437302424,
  "best_model_checkpoint": "C:/Users/Nova18/Desktop/VideoMAE/results/videomae-base--finetuned-ucf101-subset\\checkpoint-3976",
  "epoch": 3.249245472837022,
  "eval_steps": 500,
  "global_step": 3976,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 9.603394508361816,
      "learning_rate": 1.256281407035176e-06,
      "loss": 4.7134,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.894585609436035,
      "learning_rate": 2.512562814070352e-06,
      "loss": 4.6401,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 18.87928009033203,
      "learning_rate": 3.7688442211055276e-06,
      "loss": 4.6336,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.892499923706055,
      "learning_rate": 5.025125628140704e-06,
      "loss": 4.6849,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.839425086975098,
      "learning_rate": 6.2814070351758795e-06,
      "loss": 4.629,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.456535339355469,
      "learning_rate": 7.537688442211055e-06,
      "loss": 4.6837,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.900803565979004,
      "learning_rate": 8.793969849246232e-06,
      "loss": 4.6897,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.341691017150879,
      "learning_rate": 1.0050251256281408e-05,
      "loss": 4.6357,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.60416316986084,
      "learning_rate": 1.1306532663316583e-05,
      "loss": 4.5828,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.612932205200195,
      "learning_rate": 1.2562814070351759e-05,
      "loss": 4.6834,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.444699764251709,
      "learning_rate": 1.3819095477386935e-05,
      "loss": 4.5967,
      "step": 110
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.026376724243164,
      "learning_rate": 1.507537688442211e-05,
      "loss": 4.6809,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.006268501281738,
      "learning_rate": 1.6331658291457288e-05,
      "loss": 4.5466,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.641029357910156,
      "learning_rate": 1.7587939698492464e-05,
      "loss": 4.6128,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.270692825317383,
      "learning_rate": 1.884422110552764e-05,
      "loss": 4.6251,
      "step": 150
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.455266952514648,
      "learning_rate": 2.0100502512562815e-05,
      "loss": 4.548,
      "step": 160
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.3693265914917,
      "learning_rate": 2.135678391959799e-05,
      "loss": 4.6302,
      "step": 170
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.264169692993164,
      "learning_rate": 2.2613065326633167e-05,
      "loss": 4.5525,
      "step": 180
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.285093307495117,
      "learning_rate": 2.3869346733668342e-05,
      "loss": 4.4909,
      "step": 190
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.16804027557373,
      "learning_rate": 2.5125628140703518e-05,
      "loss": 4.5732,
      "step": 200
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.87396240234375,
      "learning_rate": 2.6381909547738694e-05,
      "loss": 4.5703,
      "step": 210
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.95387077331543,
      "learning_rate": 2.763819095477387e-05,
      "loss": 4.4702,
      "step": 220
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.830545425415039,
      "learning_rate": 2.8894472361809045e-05,
      "loss": 4.455,
      "step": 230
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.3661527633667,
      "learning_rate": 3.015075376884422e-05,
      "loss": 4.4167,
      "step": 240
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.951197624206543,
      "learning_rate": 3.14070351758794e-05,
      "loss": 4.4096,
      "step": 250
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.090922355651855,
      "learning_rate": 3.2663316582914576e-05,
      "loss": 4.3225,
      "step": 260
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.149579048156738,
      "learning_rate": 3.391959798994975e-05,
      "loss": 4.2923,
      "step": 270
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.840034484863281,
      "learning_rate": 3.517587939698493e-05,
      "loss": 4.293,
      "step": 280
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.597799301147461,
      "learning_rate": 3.64321608040201e-05,
      "loss": 4.2501,
      "step": 290
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.456026077270508,
      "learning_rate": 3.768844221105528e-05,
      "loss": 4.2619,
      "step": 300
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.910762786865234,
      "learning_rate": 3.8944723618090455e-05,
      "loss": 4.1663,
      "step": 310
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.171302795410156,
      "learning_rate": 4.020100502512563e-05,
      "loss": 4.2419,
      "step": 320
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.348296165466309,
      "learning_rate": 4.1457286432160806e-05,
      "loss": 4.0535,
      "step": 330
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.27777099609375,
      "learning_rate": 4.271356783919598e-05,
      "loss": 4.084,
      "step": 340
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.876968383789062,
      "learning_rate": 4.396984924623116e-05,
      "loss": 3.9483,
      "step": 350
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.428234100341797,
      "learning_rate": 4.522613065326633e-05,
      "loss": 4.1021,
      "step": 360
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.749310493469238,
      "learning_rate": 4.648241206030151e-05,
      "loss": 4.0317,
      "step": 370
    },
    {
      "epoch": 0.1,
      "grad_norm": 21.944854736328125,
      "learning_rate": 4.7738693467336685e-05,
      "loss": 3.9559,
      "step": 380
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.515604019165039,
      "learning_rate": 4.899497487437186e-05,
      "loss": 3.9158,
      "step": 390
    },
    {
      "epoch": 0.1,
      "grad_norm": 16.77326202392578,
      "learning_rate": 4.997205142537731e-05,
      "loss": 3.9257,
      "step": 400
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.010361671447754,
      "learning_rate": 4.983230855226384e-05,
      "loss": 3.9256,
      "step": 410
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.754345893859863,
      "learning_rate": 4.969256567915036e-05,
      "loss": 3.9965,
      "step": 420
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.531967163085938,
      "learning_rate": 4.9552822806036896e-05,
      "loss": 3.6247,
      "step": 430
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.642481803894043,
      "learning_rate": 4.941307993292342e-05,
      "loss": 3.9527,
      "step": 440
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.027241706848145,
      "learning_rate": 4.9273337059809954e-05,
      "loss": 3.6552,
      "step": 450
    },
    {
      "epoch": 0.12,
      "grad_norm": 10.24289321899414,
      "learning_rate": 4.913359418669648e-05,
      "loss": 3.8931,
      "step": 460
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.580730438232422,
      "learning_rate": 4.899385131358301e-05,
      "loss": 3.7791,
      "step": 470
    },
    {
      "epoch": 0.12,
      "grad_norm": 11.468093872070312,
      "learning_rate": 4.885410844046954e-05,
      "loss": 3.7425,
      "step": 480
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.68071174621582,
      "learning_rate": 4.871436556735607e-05,
      "loss": 3.6332,
      "step": 490
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.633957862854004,
      "learning_rate": 4.85746226942426e-05,
      "loss": 3.5512,
      "step": 500
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.011445999145508,
      "learning_rate": 4.843487982112912e-05,
      "loss": 3.3911,
      "step": 510
    },
    {
      "epoch": 0.13,
      "grad_norm": 10.189718246459961,
      "learning_rate": 4.829513694801565e-05,
      "loss": 3.4014,
      "step": 520
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.388531684875488,
      "learning_rate": 4.815539407490218e-05,
      "loss": 3.3213,
      "step": 530
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.998395919799805,
      "learning_rate": 4.801565120178871e-05,
      "loss": 3.416,
      "step": 540
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.926756858825684,
      "learning_rate": 4.787590832867524e-05,
      "loss": 3.3357,
      "step": 550
    },
    {
      "epoch": 0.14,
      "grad_norm": 10.98388671875,
      "learning_rate": 4.773616545556177e-05,
      "loss": 3.0511,
      "step": 560
    },
    {
      "epoch": 0.14,
      "grad_norm": 13.106827735900879,
      "learning_rate": 4.75964225824483e-05,
      "loss": 3.2874,
      "step": 570
    },
    {
      "epoch": 0.15,
      "grad_norm": 10.748991012573242,
      "learning_rate": 4.745667970933483e-05,
      "loss": 3.2291,
      "step": 580
    },
    {
      "epoch": 0.15,
      "grad_norm": 11.558619499206543,
      "learning_rate": 4.731693683622136e-05,
      "loss": 3.2137,
      "step": 590
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.136360168457031,
      "learning_rate": 4.717719396310788e-05,
      "loss": 3.1478,
      "step": 600
    },
    {
      "epoch": 0.15,
      "grad_norm": 10.917196273803711,
      "learning_rate": 4.703745108999441e-05,
      "loss": 3.1072,
      "step": 610
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.763877868652344,
      "learning_rate": 4.689770821688094e-05,
      "loss": 2.9339,
      "step": 620
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.068446159362793,
      "learning_rate": 4.675796534376747e-05,
      "loss": 3.092,
      "step": 630
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.516989707946777,
      "learning_rate": 4.6618222470654e-05,
      "loss": 2.929,
      "step": 640
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.69499683380127,
      "learning_rate": 4.6478479597540526e-05,
      "loss": 3.0179,
      "step": 650
    },
    {
      "epoch": 0.17,
      "grad_norm": 10.690152168273926,
      "learning_rate": 4.633873672442706e-05,
      "loss": 3.0373,
      "step": 660
    },
    {
      "epoch": 0.17,
      "grad_norm": 10.881625175476074,
      "learning_rate": 4.619899385131359e-05,
      "loss": 2.7711,
      "step": 670
    },
    {
      "epoch": 0.17,
      "grad_norm": 9.9005126953125,
      "learning_rate": 4.605925097820012e-05,
      "loss": 2.7809,
      "step": 680
    },
    {
      "epoch": 0.17,
      "grad_norm": 15.73772144317627,
      "learning_rate": 4.591950810508664e-05,
      "loss": 2.9028,
      "step": 690
    },
    {
      "epoch": 0.18,
      "grad_norm": 12.836578369140625,
      "learning_rate": 4.577976523197317e-05,
      "loss": 2.7807,
      "step": 700
    },
    {
      "epoch": 0.18,
      "grad_norm": 13.360228538513184,
      "learning_rate": 4.56400223588597e-05,
      "loss": 2.6214,
      "step": 710
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.599689483642578,
      "learning_rate": 4.550027948574623e-05,
      "loss": 2.407,
      "step": 720
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.646049499511719,
      "learning_rate": 4.536053661263276e-05,
      "loss": 2.6514,
      "step": 730
    },
    {
      "epoch": 0.19,
      "grad_norm": 11.15997314453125,
      "learning_rate": 4.5220793739519286e-05,
      "loss": 2.6227,
      "step": 740
    },
    {
      "epoch": 0.19,
      "grad_norm": 14.42143726348877,
      "learning_rate": 4.508105086640582e-05,
      "loss": 2.7036,
      "step": 750
    },
    {
      "epoch": 0.19,
      "grad_norm": 12.805326461791992,
      "learning_rate": 4.4941307993292344e-05,
      "loss": 2.4283,
      "step": 760
    },
    {
      "epoch": 0.19,
      "grad_norm": 11.968976020812988,
      "learning_rate": 4.480156512017887e-05,
      "loss": 2.3197,
      "step": 770
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.929729461669922,
      "learning_rate": 4.4661822247065396e-05,
      "loss": 2.3739,
      "step": 780
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.478009223937988,
      "learning_rate": 4.452207937395193e-05,
      "loss": 2.3485,
      "step": 790
    },
    {
      "epoch": 0.2,
      "grad_norm": 10.386836051940918,
      "learning_rate": 4.438233650083846e-05,
      "loss": 2.3836,
      "step": 800
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.851069450378418,
      "learning_rate": 4.424259362772499e-05,
      "loss": 2.5622,
      "step": 810
    },
    {
      "epoch": 0.21,
      "grad_norm": 13.154396057128906,
      "learning_rate": 4.410285075461152e-05,
      "loss": 2.1531,
      "step": 820
    },
    {
      "epoch": 0.21,
      "grad_norm": 10.698199272155762,
      "learning_rate": 4.3963107881498045e-05,
      "loss": 2.2752,
      "step": 830
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.846667289733887,
      "learning_rate": 4.382336500838458e-05,
      "loss": 2.1304,
      "step": 840
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.698942184448242,
      "learning_rate": 4.3683622135271104e-05,
      "loss": 2.33,
      "step": 850
    },
    {
      "epoch": 0.22,
      "grad_norm": 13.028703689575195,
      "learning_rate": 4.354387926215763e-05,
      "loss": 2.2651,
      "step": 860
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.292747497558594,
      "learning_rate": 4.3404136389044156e-05,
      "loss": 2.38,
      "step": 870
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.168082237243652,
      "learning_rate": 4.326439351593069e-05,
      "loss": 2.1683,
      "step": 880
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.583378791809082,
      "learning_rate": 4.3124650642817214e-05,
      "loss": 2.2324,
      "step": 890
    },
    {
      "epoch": 0.23,
      "grad_norm": 12.023887634277344,
      "learning_rate": 4.298490776970375e-05,
      "loss": 2.1582,
      "step": 900
    },
    {
      "epoch": 0.23,
      "grad_norm": 9.180328369140625,
      "learning_rate": 4.284516489659028e-05,
      "loss": 1.9639,
      "step": 910
    },
    {
      "epoch": 0.23,
      "grad_norm": 23.740516662597656,
      "learning_rate": 4.2705422023476805e-05,
      "loss": 2.1865,
      "step": 920
    },
    {
      "epoch": 0.23,
      "grad_norm": 14.577829360961914,
      "learning_rate": 4.256567915036334e-05,
      "loss": 2.1038,
      "step": 930
    },
    {
      "epoch": 0.24,
      "grad_norm": 10.24047565460205,
      "learning_rate": 4.2425936277249864e-05,
      "loss": 1.89,
      "step": 940
    },
    {
      "epoch": 0.24,
      "grad_norm": 11.676444053649902,
      "learning_rate": 4.228619340413639e-05,
      "loss": 2.0687,
      "step": 950
    },
    {
      "epoch": 0.24,
      "grad_norm": 13.189038276672363,
      "learning_rate": 4.2146450531022915e-05,
      "loss": 1.9283,
      "step": 960
    },
    {
      "epoch": 0.24,
      "grad_norm": 12.584705352783203,
      "learning_rate": 4.200670765790945e-05,
      "loss": 1.904,
      "step": 970
    },
    {
      "epoch": 0.25,
      "grad_norm": 19.0180606842041,
      "learning_rate": 4.1866964784795974e-05,
      "loss": 1.8698,
      "step": 980
    },
    {
      "epoch": 0.25,
      "grad_norm": 10.402120590209961,
      "learning_rate": 4.1727221911682507e-05,
      "loss": 1.7854,
      "step": 990
    },
    {
      "epoch": 0.25,
      "eval_accuracy": 0.5674394099051633,
      "eval_loss": 1.9253692626953125,
      "eval_runtime": 572.7476,
      "eval_samples_per_second": 13.255,
      "eval_steps_per_second": 1.657,
      "step": 995
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.894331932067871,
      "learning_rate": 4.158747903856903e-05,
      "loss": 1.7953,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "grad_norm": 11.06407642364502,
      "learning_rate": 4.1447736165455565e-05,
      "loss": 1.7505,
      "step": 1010
    },
    {
      "epoch": 1.01,
      "grad_norm": 10.510704040527344,
      "learning_rate": 4.130799329234209e-05,
      "loss": 1.8364,
      "step": 1020
    },
    {
      "epoch": 1.01,
      "grad_norm": 14.099393844604492,
      "learning_rate": 4.1168250419228624e-05,
      "loss": 1.844,
      "step": 1030
    },
    {
      "epoch": 1.01,
      "grad_norm": 13.455704689025879,
      "learning_rate": 4.102850754611515e-05,
      "loss": 1.9035,
      "step": 1040
    },
    {
      "epoch": 1.01,
      "grad_norm": 15.961207389831543,
      "learning_rate": 4.0888764673001675e-05,
      "loss": 2.0519,
      "step": 1050
    },
    {
      "epoch": 1.02,
      "grad_norm": 11.832886695861816,
      "learning_rate": 4.074902179988821e-05,
      "loss": 1.7491,
      "step": 1060
    },
    {
      "epoch": 1.02,
      "grad_norm": 14.08521556854248,
      "learning_rate": 4.0609278926774734e-05,
      "loss": 1.7394,
      "step": 1070
    },
    {
      "epoch": 1.02,
      "grad_norm": 12.448321342468262,
      "learning_rate": 4.0469536053661266e-05,
      "loss": 1.5972,
      "step": 1080
    },
    {
      "epoch": 1.02,
      "grad_norm": 14.33246898651123,
      "learning_rate": 4.032979318054779e-05,
      "loss": 1.6985,
      "step": 1090
    },
    {
      "epoch": 1.03,
      "grad_norm": 11.203636169433594,
      "learning_rate": 4.0190050307434325e-05,
      "loss": 1.624,
      "step": 1100
    },
    {
      "epoch": 1.03,
      "grad_norm": 11.358580589294434,
      "learning_rate": 4.005030743432085e-05,
      "loss": 1.5549,
      "step": 1110
    },
    {
      "epoch": 1.03,
      "grad_norm": 15.014886856079102,
      "learning_rate": 3.991056456120738e-05,
      "loss": 1.4536,
      "step": 1120
    },
    {
      "epoch": 1.03,
      "grad_norm": 13.484182357788086,
      "learning_rate": 3.977082168809391e-05,
      "loss": 1.7312,
      "step": 1130
    },
    {
      "epoch": 1.04,
      "grad_norm": 11.237486839294434,
      "learning_rate": 3.9631078814980435e-05,
      "loss": 1.4403,
      "step": 1140
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.038562774658203,
      "learning_rate": 3.949133594186697e-05,
      "loss": 1.5505,
      "step": 1150
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.9456205368042,
      "learning_rate": 3.9351593068753494e-05,
      "loss": 1.5707,
      "step": 1160
    },
    {
      "epoch": 1.04,
      "grad_norm": 15.982008934020996,
      "learning_rate": 3.9211850195640026e-05,
      "loss": 1.4218,
      "step": 1170
    },
    {
      "epoch": 1.05,
      "grad_norm": 10.400470733642578,
      "learning_rate": 3.907210732252655e-05,
      "loss": 1.7562,
      "step": 1180
    },
    {
      "epoch": 1.05,
      "grad_norm": 17.6069278717041,
      "learning_rate": 3.8932364449413085e-05,
      "loss": 1.4206,
      "step": 1190
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.397281646728516,
      "learning_rate": 3.879262157629961e-05,
      "loss": 1.3931,
      "step": 1200
    },
    {
      "epoch": 1.05,
      "grad_norm": 12.87075424194336,
      "learning_rate": 3.865287870318614e-05,
      "loss": 1.4979,
      "step": 1210
    },
    {
      "epoch": 1.06,
      "grad_norm": 11.7261323928833,
      "learning_rate": 3.851313583007267e-05,
      "loss": 1.4634,
      "step": 1220
    },
    {
      "epoch": 1.06,
      "grad_norm": 12.061446189880371,
      "learning_rate": 3.8373392956959195e-05,
      "loss": 1.5624,
      "step": 1230
    },
    {
      "epoch": 1.06,
      "grad_norm": 15.375714302062988,
      "learning_rate": 3.823365008384572e-05,
      "loss": 1.2595,
      "step": 1240
    },
    {
      "epoch": 1.06,
      "grad_norm": 17.425403594970703,
      "learning_rate": 3.809390721073225e-05,
      "loss": 1.6515,
      "step": 1250
    },
    {
      "epoch": 1.07,
      "grad_norm": 14.324129104614258,
      "learning_rate": 3.795416433761878e-05,
      "loss": 1.4051,
      "step": 1260
    },
    {
      "epoch": 1.07,
      "grad_norm": 14.353602409362793,
      "learning_rate": 3.781442146450531e-05,
      "loss": 1.5638,
      "step": 1270
    },
    {
      "epoch": 1.07,
      "grad_norm": 12.714990615844727,
      "learning_rate": 3.7674678591391844e-05,
      "loss": 1.4603,
      "step": 1280
    },
    {
      "epoch": 1.07,
      "grad_norm": 12.496153831481934,
      "learning_rate": 3.753493571827837e-05,
      "loss": 1.1688,
      "step": 1290
    },
    {
      "epoch": 1.08,
      "grad_norm": 14.341338157653809,
      "learning_rate": 3.73951928451649e-05,
      "loss": 1.2048,
      "step": 1300
    },
    {
      "epoch": 1.08,
      "grad_norm": 13.913039207458496,
      "learning_rate": 3.725544997205143e-05,
      "loss": 1.1861,
      "step": 1310
    },
    {
      "epoch": 1.08,
      "grad_norm": 12.303367614746094,
      "learning_rate": 3.7115707098937955e-05,
      "loss": 1.4002,
      "step": 1320
    },
    {
      "epoch": 1.08,
      "grad_norm": 23.312103271484375,
      "learning_rate": 3.697596422582448e-05,
      "loss": 1.4525,
      "step": 1330
    },
    {
      "epoch": 1.09,
      "grad_norm": 9.175825119018555,
      "learning_rate": 3.683622135271101e-05,
      "loss": 1.2522,
      "step": 1340
    },
    {
      "epoch": 1.09,
      "grad_norm": 10.539546012878418,
      "learning_rate": 3.669647847959754e-05,
      "loss": 1.3688,
      "step": 1350
    },
    {
      "epoch": 1.09,
      "grad_norm": 8.336791038513184,
      "learning_rate": 3.655673560648407e-05,
      "loss": 1.3528,
      "step": 1360
    },
    {
      "epoch": 1.09,
      "grad_norm": 13.459769248962402,
      "learning_rate": 3.64169927333706e-05,
      "loss": 1.1535,
      "step": 1370
    },
    {
      "epoch": 1.1,
      "grad_norm": 14.721117973327637,
      "learning_rate": 3.627724986025713e-05,
      "loss": 1.2963,
      "step": 1380
    },
    {
      "epoch": 1.1,
      "grad_norm": 11.803976058959961,
      "learning_rate": 3.613750698714366e-05,
      "loss": 1.1872,
      "step": 1390
    },
    {
      "epoch": 1.1,
      "grad_norm": 10.801596641540527,
      "learning_rate": 3.599776411403019e-05,
      "loss": 1.2017,
      "step": 1400
    },
    {
      "epoch": 1.1,
      "grad_norm": 8.822267532348633,
      "learning_rate": 3.5858021240916714e-05,
      "loss": 1.1496,
      "step": 1410
    },
    {
      "epoch": 1.11,
      "grad_norm": 9.283431053161621,
      "learning_rate": 3.571827836780324e-05,
      "loss": 1.3199,
      "step": 1420
    },
    {
      "epoch": 1.11,
      "grad_norm": 14.596290588378906,
      "learning_rate": 3.557853549468977e-05,
      "loss": 1.1822,
      "step": 1430
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.632736206054688,
      "learning_rate": 3.54387926215763e-05,
      "loss": 1.2341,
      "step": 1440
    },
    {
      "epoch": 1.11,
      "grad_norm": 15.748701095581055,
      "learning_rate": 3.529904974846283e-05,
      "loss": 0.963,
      "step": 1450
    },
    {
      "epoch": 1.12,
      "grad_norm": 12.893333435058594,
      "learning_rate": 3.515930687534936e-05,
      "loss": 0.9838,
      "step": 1460
    },
    {
      "epoch": 1.12,
      "grad_norm": 17.149084091186523,
      "learning_rate": 3.501956400223589e-05,
      "loss": 1.0593,
      "step": 1470
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.917800903320312,
      "learning_rate": 3.4879821129122416e-05,
      "loss": 1.2475,
      "step": 1480
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.677220344543457,
      "learning_rate": 3.474007825600895e-05,
      "loss": 1.1957,
      "step": 1490
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.694352149963379,
      "learning_rate": 3.4600335382895474e-05,
      "loss": 1.1117,
      "step": 1500
    },
    {
      "epoch": 1.13,
      "grad_norm": 6.680263519287109,
      "learning_rate": 3.4460592509782e-05,
      "loss": 0.8861,
      "step": 1510
    },
    {
      "epoch": 1.13,
      "grad_norm": 11.77731704711914,
      "learning_rate": 3.432084963666853e-05,
      "loss": 1.0154,
      "step": 1520
    },
    {
      "epoch": 1.13,
      "grad_norm": 10.393549919128418,
      "learning_rate": 3.418110676355506e-05,
      "loss": 0.9884,
      "step": 1530
    },
    {
      "epoch": 1.14,
      "grad_norm": 13.247411727905273,
      "learning_rate": 3.404136389044159e-05,
      "loss": 1.0967,
      "step": 1540
    },
    {
      "epoch": 1.14,
      "grad_norm": 23.011314392089844,
      "learning_rate": 3.390162101732812e-05,
      "loss": 0.9145,
      "step": 1550
    },
    {
      "epoch": 1.14,
      "grad_norm": 23.958498001098633,
      "learning_rate": 3.376187814421465e-05,
      "loss": 0.9795,
      "step": 1560
    },
    {
      "epoch": 1.14,
      "grad_norm": 9.74586009979248,
      "learning_rate": 3.3622135271101176e-05,
      "loss": 1.0212,
      "step": 1570
    },
    {
      "epoch": 1.15,
      "grad_norm": 12.833098411560059,
      "learning_rate": 3.348239239798771e-05,
      "loss": 0.9973,
      "step": 1580
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.4789042472839355,
      "learning_rate": 3.3342649524874234e-05,
      "loss": 0.9418,
      "step": 1590
    },
    {
      "epoch": 1.15,
      "grad_norm": 14.857219696044922,
      "learning_rate": 3.320290665176076e-05,
      "loss": 1.1064,
      "step": 1600
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.2190632820129395,
      "learning_rate": 3.3063163778647286e-05,
      "loss": 0.9078,
      "step": 1610
    },
    {
      "epoch": 1.16,
      "grad_norm": 11.25068187713623,
      "learning_rate": 3.292342090553382e-05,
      "loss": 1.0263,
      "step": 1620
    },
    {
      "epoch": 1.16,
      "grad_norm": 9.721518516540527,
      "learning_rate": 3.278367803242035e-05,
      "loss": 0.9963,
      "step": 1630
    },
    {
      "epoch": 1.16,
      "grad_norm": 12.073233604431152,
      "learning_rate": 3.264393515930688e-05,
      "loss": 1.0925,
      "step": 1640
    },
    {
      "epoch": 1.16,
      "grad_norm": 10.046216011047363,
      "learning_rate": 3.250419228619341e-05,
      "loss": 0.8304,
      "step": 1650
    },
    {
      "epoch": 1.17,
      "grad_norm": 16.29368019104004,
      "learning_rate": 3.2364449413079935e-05,
      "loss": 0.9415,
      "step": 1660
    },
    {
      "epoch": 1.17,
      "grad_norm": 9.99484920501709,
      "learning_rate": 3.222470653996647e-05,
      "loss": 0.9601,
      "step": 1670
    },
    {
      "epoch": 1.17,
      "grad_norm": 10.168293952941895,
      "learning_rate": 3.2084963666852994e-05,
      "loss": 0.8477,
      "step": 1680
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.872888565063477,
      "learning_rate": 3.194522079373952e-05,
      "loss": 0.8964,
      "step": 1690
    },
    {
      "epoch": 1.18,
      "grad_norm": 12.035773277282715,
      "learning_rate": 3.1805477920626046e-05,
      "loss": 0.8127,
      "step": 1700
    },
    {
      "epoch": 1.18,
      "grad_norm": 5.542326927185059,
      "learning_rate": 3.166573504751258e-05,
      "loss": 0.7484,
      "step": 1710
    },
    {
      "epoch": 1.18,
      "grad_norm": 7.8117828369140625,
      "learning_rate": 3.1525992174399104e-05,
      "loss": 0.7508,
      "step": 1720
    },
    {
      "epoch": 1.18,
      "grad_norm": 19.08527946472168,
      "learning_rate": 3.138624930128564e-05,
      "loss": 0.7462,
      "step": 1730
    },
    {
      "epoch": 1.19,
      "grad_norm": 13.46273136138916,
      "learning_rate": 3.124650642817216e-05,
      "loss": 0.8643,
      "step": 1740
    },
    {
      "epoch": 1.19,
      "grad_norm": 13.612189292907715,
      "learning_rate": 3.1106763555058695e-05,
      "loss": 0.7616,
      "step": 1750
    },
    {
      "epoch": 1.19,
      "grad_norm": 9.31195068359375,
      "learning_rate": 3.096702068194523e-05,
      "loss": 0.69,
      "step": 1760
    },
    {
      "epoch": 1.19,
      "grad_norm": 8.470447540283203,
      "learning_rate": 3.0827277808831754e-05,
      "loss": 0.824,
      "step": 1770
    },
    {
      "epoch": 1.2,
      "grad_norm": 11.159187316894531,
      "learning_rate": 3.068753493571828e-05,
      "loss": 0.8401,
      "step": 1780
    },
    {
      "epoch": 1.2,
      "grad_norm": 9.541216850280762,
      "learning_rate": 3.0547792062604805e-05,
      "loss": 0.6627,
      "step": 1790
    },
    {
      "epoch": 1.2,
      "grad_norm": 15.387859344482422,
      "learning_rate": 3.0408049189491338e-05,
      "loss": 0.8965,
      "step": 1800
    },
    {
      "epoch": 1.2,
      "grad_norm": 11.047063827514648,
      "learning_rate": 3.0268306316377864e-05,
      "loss": 0.8314,
      "step": 1810
    },
    {
      "epoch": 1.21,
      "grad_norm": 19.8657169342041,
      "learning_rate": 3.0128563443264397e-05,
      "loss": 0.8689,
      "step": 1820
    },
    {
      "epoch": 1.21,
      "grad_norm": 12.957269668579102,
      "learning_rate": 2.9988820570150922e-05,
      "loss": 0.8029,
      "step": 1830
    },
    {
      "epoch": 1.21,
      "grad_norm": 12.25037956237793,
      "learning_rate": 2.984907769703745e-05,
      "loss": 0.8508,
      "step": 1840
    },
    {
      "epoch": 1.22,
      "grad_norm": 13.123977661132812,
      "learning_rate": 2.9709334823923978e-05,
      "loss": 0.7232,
      "step": 1850
    },
    {
      "epoch": 1.22,
      "grad_norm": 11.779766082763672,
      "learning_rate": 2.956959195081051e-05,
      "loss": 0.9318,
      "step": 1860
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.846174716949463,
      "learning_rate": 2.9429849077697043e-05,
      "loss": 0.7492,
      "step": 1870
    },
    {
      "epoch": 1.22,
      "grad_norm": 18.544178009033203,
      "learning_rate": 2.929010620458357e-05,
      "loss": 1.0301,
      "step": 1880
    },
    {
      "epoch": 1.23,
      "grad_norm": 12.396848678588867,
      "learning_rate": 2.9150363331470098e-05,
      "loss": 0.7437,
      "step": 1890
    },
    {
      "epoch": 1.23,
      "grad_norm": 13.736759185791016,
      "learning_rate": 2.9010620458356624e-05,
      "loss": 0.6933,
      "step": 1900
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.685007572174072,
      "learning_rate": 2.8870877585243156e-05,
      "loss": 0.6947,
      "step": 1910
    },
    {
      "epoch": 1.23,
      "grad_norm": 27.3133487701416,
      "learning_rate": 2.8731134712129682e-05,
      "loss": 0.6768,
      "step": 1920
    },
    {
      "epoch": 1.24,
      "grad_norm": 9.761689186096191,
      "learning_rate": 2.859139183901621e-05,
      "loss": 0.7089,
      "step": 1930
    },
    {
      "epoch": 1.24,
      "grad_norm": 11.483105659484863,
      "learning_rate": 2.8451648965902737e-05,
      "loss": 0.644,
      "step": 1940
    },
    {
      "epoch": 1.24,
      "grad_norm": 11.887090682983398,
      "learning_rate": 2.831190609278927e-05,
      "loss": 0.9186,
      "step": 1950
    },
    {
      "epoch": 1.24,
      "grad_norm": 11.471877098083496,
      "learning_rate": 2.8172163219675796e-05,
      "loss": 0.6193,
      "step": 1960
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.644511222839355,
      "learning_rate": 2.803242034656233e-05,
      "loss": 0.7065,
      "step": 1970
    },
    {
      "epoch": 1.25,
      "grad_norm": 10.651188850402832,
      "learning_rate": 2.7892677473448854e-05,
      "loss": 0.8331,
      "step": 1980
    },
    {
      "epoch": 1.25,
      "grad_norm": 18.25551414489746,
      "learning_rate": 2.7752934600335384e-05,
      "loss": 0.6025,
      "step": 1990
    },
    {
      "epoch": 1.25,
      "eval_accuracy": 0.8043993677555321,
      "eval_loss": 0.7975683212280273,
      "eval_runtime": 562.5766,
      "eval_samples_per_second": 13.495,
      "eval_steps_per_second": 1.687,
      "step": 1990
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.056784629821777,
      "learning_rate": 2.7613191727221916e-05,
      "loss": 0.6064,
      "step": 2000
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.606557846069336,
      "learning_rate": 2.7473448854108442e-05,
      "loss": 0.677,
      "step": 2010
    },
    {
      "epoch": 2.01,
      "grad_norm": 10.31021499633789,
      "learning_rate": 2.733370598099497e-05,
      "loss": 0.6019,
      "step": 2020
    },
    {
      "epoch": 2.01,
      "grad_norm": 9.03647232055664,
      "learning_rate": 2.7193963107881497e-05,
      "loss": 0.573,
      "step": 2030
    },
    {
      "epoch": 2.01,
      "grad_norm": 15.1275053024292,
      "learning_rate": 2.705422023476803e-05,
      "loss": 0.4664,
      "step": 2040
    },
    {
      "epoch": 2.02,
      "grad_norm": 8.516027450561523,
      "learning_rate": 2.6914477361654556e-05,
      "loss": 0.5705,
      "step": 2050
    },
    {
      "epoch": 2.02,
      "grad_norm": 15.343503952026367,
      "learning_rate": 2.6774734488541088e-05,
      "loss": 0.5145,
      "step": 2060
    },
    {
      "epoch": 2.02,
      "grad_norm": 14.818634986877441,
      "learning_rate": 2.6634991615427614e-05,
      "loss": 0.5625,
      "step": 2070
    },
    {
      "epoch": 2.02,
      "grad_norm": 7.4699788093566895,
      "learning_rate": 2.6495248742314143e-05,
      "loss": 0.5152,
      "step": 2080
    },
    {
      "epoch": 2.03,
      "grad_norm": 13.669334411621094,
      "learning_rate": 2.635550586920067e-05,
      "loss": 0.5954,
      "step": 2090
    },
    {
      "epoch": 2.03,
      "grad_norm": 10.398585319519043,
      "learning_rate": 2.6215762996087202e-05,
      "loss": 0.7713,
      "step": 2100
    },
    {
      "epoch": 2.03,
      "grad_norm": 13.553613662719727,
      "learning_rate": 2.607602012297373e-05,
      "loss": 0.5332,
      "step": 2110
    },
    {
      "epoch": 2.03,
      "grad_norm": 10.51949405670166,
      "learning_rate": 2.5936277249860257e-05,
      "loss": 0.6118,
      "step": 2120
    },
    {
      "epoch": 2.04,
      "grad_norm": 7.01741886138916,
      "learning_rate": 2.579653437674679e-05,
      "loss": 0.4744,
      "step": 2130
    },
    {
      "epoch": 2.04,
      "grad_norm": 16.350574493408203,
      "learning_rate": 2.5656791503633315e-05,
      "loss": 0.5986,
      "step": 2140
    },
    {
      "epoch": 2.04,
      "grad_norm": 9.108689308166504,
      "learning_rate": 2.5517048630519848e-05,
      "loss": 0.7941,
      "step": 2150
    },
    {
      "epoch": 2.04,
      "grad_norm": 8.870694160461426,
      "learning_rate": 2.537730575740637e-05,
      "loss": 0.6477,
      "step": 2160
    },
    {
      "epoch": 2.05,
      "grad_norm": 15.520601272583008,
      "learning_rate": 2.5237562884292903e-05,
      "loss": 0.6257,
      "step": 2170
    },
    {
      "epoch": 2.05,
      "grad_norm": 10.656989097595215,
      "learning_rate": 2.509782001117943e-05,
      "loss": 0.6195,
      "step": 2180
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.755983352661133,
      "learning_rate": 2.495807713806596e-05,
      "loss": 0.3774,
      "step": 2190
    },
    {
      "epoch": 2.05,
      "grad_norm": 7.816165447235107,
      "learning_rate": 2.4818334264952488e-05,
      "loss": 0.5633,
      "step": 2200
    },
    {
      "epoch": 2.06,
      "grad_norm": 9.878504753112793,
      "learning_rate": 2.4678591391839017e-05,
      "loss": 0.4401,
      "step": 2210
    },
    {
      "epoch": 2.06,
      "grad_norm": 10.48438549041748,
      "learning_rate": 2.4538848518725546e-05,
      "loss": 0.7646,
      "step": 2220
    },
    {
      "epoch": 2.06,
      "grad_norm": 9.541324615478516,
      "learning_rate": 2.4399105645612075e-05,
      "loss": 0.5176,
      "step": 2230
    },
    {
      "epoch": 2.06,
      "grad_norm": 10.772208213806152,
      "learning_rate": 2.4259362772498604e-05,
      "loss": 0.5063,
      "step": 2240
    },
    {
      "epoch": 2.07,
      "grad_norm": 11.37989330291748,
      "learning_rate": 2.411961989938513e-05,
      "loss": 0.7475,
      "step": 2250
    },
    {
      "epoch": 2.07,
      "grad_norm": 9.771841049194336,
      "learning_rate": 2.397987702627166e-05,
      "loss": 0.4666,
      "step": 2260
    },
    {
      "epoch": 2.07,
      "grad_norm": 6.943944454193115,
      "learning_rate": 2.384013415315819e-05,
      "loss": 0.4867,
      "step": 2270
    },
    {
      "epoch": 2.07,
      "grad_norm": 11.62909984588623,
      "learning_rate": 2.3700391280044718e-05,
      "loss": 0.5144,
      "step": 2280
    },
    {
      "epoch": 2.08,
      "grad_norm": 7.13170862197876,
      "learning_rate": 2.3560648406931247e-05,
      "loss": 0.4869,
      "step": 2290
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.754109382629395,
      "learning_rate": 2.3420905533817777e-05,
      "loss": 0.5611,
      "step": 2300
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.701139450073242,
      "learning_rate": 2.3281162660704306e-05,
      "loss": 0.4706,
      "step": 2310
    },
    {
      "epoch": 2.08,
      "grad_norm": 9.733358383178711,
      "learning_rate": 2.3141419787590835e-05,
      "loss": 0.4313,
      "step": 2320
    },
    {
      "epoch": 2.09,
      "grad_norm": 8.001922607421875,
      "learning_rate": 2.3001676914477364e-05,
      "loss": 0.3982,
      "step": 2330
    },
    {
      "epoch": 2.09,
      "grad_norm": 15.74398136138916,
      "learning_rate": 2.286193404136389e-05,
      "loss": 0.5932,
      "step": 2340
    },
    {
      "epoch": 2.09,
      "grad_norm": 8.962845802307129,
      "learning_rate": 2.272219116825042e-05,
      "loss": 0.4962,
      "step": 2350
    },
    {
      "epoch": 2.09,
      "grad_norm": 11.446768760681152,
      "learning_rate": 2.258244829513695e-05,
      "loss": 0.4823,
      "step": 2360
    },
    {
      "epoch": 2.1,
      "grad_norm": 17.319047927856445,
      "learning_rate": 2.2442705422023478e-05,
      "loss": 0.3745,
      "step": 2370
    },
    {
      "epoch": 2.1,
      "grad_norm": 7.198819637298584,
      "learning_rate": 2.2302962548910007e-05,
      "loss": 0.5265,
      "step": 2380
    },
    {
      "epoch": 2.1,
      "grad_norm": 8.515018463134766,
      "learning_rate": 2.2163219675796533e-05,
      "loss": 0.409,
      "step": 2390
    },
    {
      "epoch": 2.1,
      "grad_norm": 11.986286163330078,
      "learning_rate": 2.2023476802683062e-05,
      "loss": 0.5329,
      "step": 2400
    },
    {
      "epoch": 2.11,
      "grad_norm": 10.433640480041504,
      "learning_rate": 2.1883733929569595e-05,
      "loss": 0.4174,
      "step": 2410
    },
    {
      "epoch": 2.11,
      "grad_norm": 15.171673774719238,
      "learning_rate": 2.1743991056456124e-05,
      "loss": 0.5416,
      "step": 2420
    },
    {
      "epoch": 2.11,
      "grad_norm": 11.66644287109375,
      "learning_rate": 2.160424818334265e-05,
      "loss": 0.4655,
      "step": 2430
    },
    {
      "epoch": 2.11,
      "grad_norm": 4.994950771331787,
      "learning_rate": 2.146450531022918e-05,
      "loss": 0.533,
      "step": 2440
    },
    {
      "epoch": 2.12,
      "grad_norm": 6.583167552947998,
      "learning_rate": 2.132476243711571e-05,
      "loss": 0.3507,
      "step": 2450
    },
    {
      "epoch": 2.12,
      "grad_norm": 7.650384426116943,
      "learning_rate": 2.1185019564002238e-05,
      "loss": 0.4914,
      "step": 2460
    },
    {
      "epoch": 2.12,
      "grad_norm": 12.476151466369629,
      "learning_rate": 2.1045276690888767e-05,
      "loss": 0.4673,
      "step": 2470
    },
    {
      "epoch": 2.12,
      "grad_norm": 13.00597095489502,
      "learning_rate": 2.0905533817775293e-05,
      "loss": 0.4229,
      "step": 2480
    },
    {
      "epoch": 2.13,
      "grad_norm": 9.669461250305176,
      "learning_rate": 2.0765790944661822e-05,
      "loss": 0.45,
      "step": 2490
    },
    {
      "epoch": 2.13,
      "grad_norm": 21.307252883911133,
      "learning_rate": 2.062604807154835e-05,
      "loss": 0.3735,
      "step": 2500
    },
    {
      "epoch": 2.13,
      "grad_norm": 18.149505615234375,
      "learning_rate": 2.048630519843488e-05,
      "loss": 0.4043,
      "step": 2510
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.1178479194641113,
      "learning_rate": 2.034656232532141e-05,
      "loss": 0.3753,
      "step": 2520
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.6079180240631104,
      "learning_rate": 2.020681945220794e-05,
      "loss": 0.3929,
      "step": 2530
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.675140619277954,
      "learning_rate": 2.0067076579094468e-05,
      "loss": 0.2614,
      "step": 2540
    },
    {
      "epoch": 2.14,
      "grad_norm": 14.565773010253906,
      "learning_rate": 1.9927333705980998e-05,
      "loss": 0.4287,
      "step": 2550
    },
    {
      "epoch": 2.14,
      "grad_norm": 11.05378532409668,
      "learning_rate": 1.9787590832867527e-05,
      "loss": 0.3434,
      "step": 2560
    },
    {
      "epoch": 2.15,
      "grad_norm": 11.171858787536621,
      "learning_rate": 1.9647847959754053e-05,
      "loss": 0.4391,
      "step": 2570
    },
    {
      "epoch": 2.15,
      "grad_norm": 4.270205020904541,
      "learning_rate": 1.9508105086640582e-05,
      "loss": 0.524,
      "step": 2580
    },
    {
      "epoch": 2.15,
      "grad_norm": 5.487610340118408,
      "learning_rate": 1.936836221352711e-05,
      "loss": 0.3764,
      "step": 2590
    },
    {
      "epoch": 2.15,
      "grad_norm": 18.001731872558594,
      "learning_rate": 1.922861934041364e-05,
      "loss": 0.377,
      "step": 2600
    },
    {
      "epoch": 2.16,
      "grad_norm": 6.897763729095459,
      "learning_rate": 1.908887646730017e-05,
      "loss": 0.2978,
      "step": 2610
    },
    {
      "epoch": 2.16,
      "grad_norm": 14.62015438079834,
      "learning_rate": 1.8949133594186695e-05,
      "loss": 0.3753,
      "step": 2620
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.162179946899414,
      "learning_rate": 1.8809390721073225e-05,
      "loss": 0.3789,
      "step": 2630
    },
    {
      "epoch": 2.16,
      "grad_norm": 6.068413734436035,
      "learning_rate": 1.8669647847959754e-05,
      "loss": 0.4853,
      "step": 2640
    },
    {
      "epoch": 2.17,
      "grad_norm": 12.940986633300781,
      "learning_rate": 1.8529904974846287e-05,
      "loss": 0.401,
      "step": 2650
    },
    {
      "epoch": 2.17,
      "grad_norm": 9.10816478729248,
      "learning_rate": 1.8390162101732812e-05,
      "loss": 0.3497,
      "step": 2660
    },
    {
      "epoch": 2.17,
      "grad_norm": 12.1830472946167,
      "learning_rate": 1.825041922861934e-05,
      "loss": 0.5627,
      "step": 2670
    },
    {
      "epoch": 2.17,
      "grad_norm": 22.007282257080078,
      "learning_rate": 1.811067635550587e-05,
      "loss": 0.2316,
      "step": 2680
    },
    {
      "epoch": 2.18,
      "grad_norm": 5.124590873718262,
      "learning_rate": 1.79709334823924e-05,
      "loss": 0.3947,
      "step": 2690
    },
    {
      "epoch": 2.18,
      "grad_norm": 14.406204223632812,
      "learning_rate": 1.7831190609278926e-05,
      "loss": 0.5104,
      "step": 2700
    },
    {
      "epoch": 2.18,
      "grad_norm": 22.148038864135742,
      "learning_rate": 1.7691447736165455e-05,
      "loss": 0.2378,
      "step": 2710
    },
    {
      "epoch": 2.18,
      "grad_norm": 8.578245162963867,
      "learning_rate": 1.7551704863051985e-05,
      "loss": 0.3182,
      "step": 2720
    },
    {
      "epoch": 2.19,
      "grad_norm": 10.78282642364502,
      "learning_rate": 1.7411961989938514e-05,
      "loss": 0.5462,
      "step": 2730
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.714298963546753,
      "learning_rate": 1.7272219116825043e-05,
      "loss": 0.3165,
      "step": 2740
    },
    {
      "epoch": 2.19,
      "grad_norm": 21.536611557006836,
      "learning_rate": 1.713247624371157e-05,
      "loss": 0.4444,
      "step": 2750
    },
    {
      "epoch": 2.19,
      "grad_norm": 18.327564239501953,
      "learning_rate": 1.6992733370598098e-05,
      "loss": 0.4562,
      "step": 2760
    },
    {
      "epoch": 2.2,
      "grad_norm": 17.03891944885254,
      "learning_rate": 1.685299049748463e-05,
      "loss": 0.4789,
      "step": 2770
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.3581089973449707,
      "learning_rate": 1.671324762437116e-05,
      "loss": 0.448,
      "step": 2780
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.692131996154785,
      "learning_rate": 1.6573504751257686e-05,
      "loss": 0.3627,
      "step": 2790
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.5810513496398926,
      "learning_rate": 1.6433761878144215e-05,
      "loss": 0.3608,
      "step": 2800
    },
    {
      "epoch": 2.21,
      "grad_norm": 3.905592918395996,
      "learning_rate": 1.6294019005030744e-05,
      "loss": 0.2344,
      "step": 2810
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.697725534439087,
      "learning_rate": 1.6154276131917274e-05,
      "loss": 0.3901,
      "step": 2820
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.774866819381714,
      "learning_rate": 1.6014533258803803e-05,
      "loss": 0.2331,
      "step": 2830
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.5737123489379883,
      "learning_rate": 1.587479038569033e-05,
      "loss": 0.4411,
      "step": 2840
    },
    {
      "epoch": 2.22,
      "grad_norm": 10.341869354248047,
      "learning_rate": 1.5735047512576858e-05,
      "loss": 0.358,
      "step": 2850
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.3605003356933594,
      "learning_rate": 1.5595304639463387e-05,
      "loss": 0.3361,
      "step": 2860
    },
    {
      "epoch": 2.22,
      "grad_norm": 5.700618267059326,
      "learning_rate": 1.5455561766349916e-05,
      "loss": 0.277,
      "step": 2870
    },
    {
      "epoch": 2.22,
      "grad_norm": 12.295673370361328,
      "learning_rate": 1.5315818893236446e-05,
      "loss": 0.2413,
      "step": 2880
    },
    {
      "epoch": 2.23,
      "grad_norm": 15.668057441711426,
      "learning_rate": 1.5176076020122975e-05,
      "loss": 0.3975,
      "step": 2890
    },
    {
      "epoch": 2.23,
      "grad_norm": 4.278310298919678,
      "learning_rate": 1.5036333147009504e-05,
      "loss": 0.289,
      "step": 2900
    },
    {
      "epoch": 2.23,
      "grad_norm": 11.971272468566895,
      "learning_rate": 1.4896590273896033e-05,
      "loss": 0.3751,
      "step": 2910
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.303088426589966,
      "learning_rate": 1.4756847400782561e-05,
      "loss": 0.2746,
      "step": 2920
    },
    {
      "epoch": 2.24,
      "grad_norm": 16.185571670532227,
      "learning_rate": 1.461710452766909e-05,
      "loss": 0.3296,
      "step": 2930
    },
    {
      "epoch": 2.24,
      "grad_norm": 10.288942337036133,
      "learning_rate": 1.4477361654555618e-05,
      "loss": 0.28,
      "step": 2940
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.8435938358306885,
      "learning_rate": 1.4337618781442147e-05,
      "loss": 0.3501,
      "step": 2950
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.8890678882598877,
      "learning_rate": 1.4197875908328676e-05,
      "loss": 0.2445,
      "step": 2960
    },
    {
      "epoch": 2.25,
      "grad_norm": 5.0801591873168945,
      "learning_rate": 1.4058133035215204e-05,
      "loss": 0.3025,
      "step": 2970
    },
    {
      "epoch": 2.25,
      "grad_norm": 17.609743118286133,
      "learning_rate": 1.3918390162101733e-05,
      "loss": 0.2087,
      "step": 2980
    },
    {
      "epoch": 2.25,
      "eval_accuracy": 0.8843519494204426,
      "eval_loss": 0.4447905719280243,
      "eval_runtime": 565.2859,
      "eval_samples_per_second": 13.43,
      "eval_steps_per_second": 1.679,
      "step": 2985
    },
    {
      "epoch": 3.0,
      "grad_norm": 23.02250099182129,
      "learning_rate": 1.377864728898826e-05,
      "loss": 0.2491,
      "step": 2990
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.015173435211182,
      "learning_rate": 1.363890441587479e-05,
      "loss": 0.2852,
      "step": 3000
    },
    {
      "epoch": 3.01,
      "grad_norm": 5.085008144378662,
      "learning_rate": 1.349916154276132e-05,
      "loss": 0.2495,
      "step": 3010
    },
    {
      "epoch": 3.01,
      "grad_norm": 8.579426765441895,
      "learning_rate": 1.335941866964785e-05,
      "loss": 0.2072,
      "step": 3020
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.310338258743286,
      "learning_rate": 1.3219675796534378e-05,
      "loss": 0.2174,
      "step": 3030
    },
    {
      "epoch": 3.01,
      "grad_norm": 8.185006141662598,
      "learning_rate": 1.3079932923420907e-05,
      "loss": 0.3369,
      "step": 3040
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.0722525119781494,
      "learning_rate": 1.2940190050307436e-05,
      "loss": 0.2972,
      "step": 3050
    },
    {
      "epoch": 3.02,
      "grad_norm": 4.525216579437256,
      "learning_rate": 1.2800447177193964e-05,
      "loss": 0.2201,
      "step": 3060
    },
    {
      "epoch": 3.02,
      "grad_norm": 5.041592597961426,
      "learning_rate": 1.2660704304080493e-05,
      "loss": 0.1991,
      "step": 3070
    },
    {
      "epoch": 3.02,
      "grad_norm": 35.917633056640625,
      "learning_rate": 1.252096143096702e-05,
      "loss": 0.2548,
      "step": 3080
    },
    {
      "epoch": 3.03,
      "grad_norm": 11.966143608093262,
      "learning_rate": 1.238121855785355e-05,
      "loss": 0.3226,
      "step": 3090
    },
    {
      "epoch": 3.03,
      "grad_norm": 5.81975793838501,
      "learning_rate": 1.2241475684740079e-05,
      "loss": 0.246,
      "step": 3100
    },
    {
      "epoch": 3.03,
      "grad_norm": 11.577756881713867,
      "learning_rate": 1.2101732811626608e-05,
      "loss": 0.2701,
      "step": 3110
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.8221027851104736,
      "learning_rate": 1.1961989938513136e-05,
      "loss": 0.2856,
      "step": 3120
    },
    {
      "epoch": 3.04,
      "grad_norm": 13.33424186706543,
      "learning_rate": 1.1822247065399665e-05,
      "loss": 0.3198,
      "step": 3130
    },
    {
      "epoch": 3.04,
      "grad_norm": 12.961906433105469,
      "learning_rate": 1.1682504192286194e-05,
      "loss": 0.2845,
      "step": 3140
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.9263602495193481,
      "learning_rate": 1.1542761319172722e-05,
      "loss": 0.1328,
      "step": 3150
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.1707119941711426,
      "learning_rate": 1.1403018446059253e-05,
      "loss": 0.2654,
      "step": 3160
    },
    {
      "epoch": 3.05,
      "grad_norm": 19.092098236083984,
      "learning_rate": 1.126327557294578e-05,
      "loss": 0.1989,
      "step": 3170
    },
    {
      "epoch": 3.05,
      "grad_norm": 16.4052677154541,
      "learning_rate": 1.112353269983231e-05,
      "loss": 0.2351,
      "step": 3180
    },
    {
      "epoch": 3.05,
      "grad_norm": 14.995100975036621,
      "learning_rate": 1.0983789826718837e-05,
      "loss": 0.2469,
      "step": 3190
    },
    {
      "epoch": 3.05,
      "grad_norm": 7.349833011627197,
      "learning_rate": 1.0844046953605366e-05,
      "loss": 0.1791,
      "step": 3200
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.8124223947525024,
      "learning_rate": 1.0704304080491895e-05,
      "loss": 0.1707,
      "step": 3210
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.0313968658447266,
      "learning_rate": 1.0564561207378425e-05,
      "loss": 0.1827,
      "step": 3220
    },
    {
      "epoch": 3.06,
      "grad_norm": 10.098546028137207,
      "learning_rate": 1.0424818334264954e-05,
      "loss": 0.2814,
      "step": 3230
    },
    {
      "epoch": 3.06,
      "grad_norm": 9.928322792053223,
      "learning_rate": 1.0285075461151481e-05,
      "loss": 0.1952,
      "step": 3240
    },
    {
      "epoch": 3.07,
      "grad_norm": 3.41499924659729,
      "learning_rate": 1.014533258803801e-05,
      "loss": 0.2935,
      "step": 3250
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.393663614988327,
      "learning_rate": 1.0005589714924538e-05,
      "loss": 0.1931,
      "step": 3260
    },
    {
      "epoch": 3.07,
      "grad_norm": 15.299490928649902,
      "learning_rate": 9.865846841811068e-06,
      "loss": 0.2749,
      "step": 3270
    },
    {
      "epoch": 3.07,
      "grad_norm": 7.443324565887451,
      "learning_rate": 9.726103968697597e-06,
      "loss": 0.1842,
      "step": 3280
    },
    {
      "epoch": 3.08,
      "grad_norm": 18.29060173034668,
      "learning_rate": 9.586361095584126e-06,
      "loss": 0.192,
      "step": 3290
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.7067668437957764,
      "learning_rate": 9.446618222470655e-06,
      "loss": 0.1518,
      "step": 3300
    },
    {
      "epoch": 3.08,
      "grad_norm": 10.988340377807617,
      "learning_rate": 9.306875349357183e-06,
      "loss": 0.2729,
      "step": 3310
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.225797176361084,
      "learning_rate": 9.167132476243712e-06,
      "loss": 0.2527,
      "step": 3320
    },
    {
      "epoch": 3.09,
      "grad_norm": 5.179957866668701,
      "learning_rate": 9.02738960313024e-06,
      "loss": 0.2471,
      "step": 3330
    },
    {
      "epoch": 3.09,
      "grad_norm": 14.470011711120605,
      "learning_rate": 8.88764673001677e-06,
      "loss": 0.3099,
      "step": 3340
    },
    {
      "epoch": 3.09,
      "grad_norm": 2.1762583255767822,
      "learning_rate": 8.747903856903298e-06,
      "loss": 0.2119,
      "step": 3350
    },
    {
      "epoch": 3.09,
      "grad_norm": 19.55530548095703,
      "learning_rate": 8.608160983789827e-06,
      "loss": 0.0965,
      "step": 3360
    },
    {
      "epoch": 3.1,
      "grad_norm": 13.984518051147461,
      "learning_rate": 8.468418110676357e-06,
      "loss": 0.1718,
      "step": 3370
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.989975690841675,
      "learning_rate": 8.328675237562884e-06,
      "loss": 0.1476,
      "step": 3380
    },
    {
      "epoch": 3.1,
      "grad_norm": 10.98697566986084,
      "learning_rate": 8.188932364449413e-06,
      "loss": 0.1603,
      "step": 3390
    },
    {
      "epoch": 3.1,
      "grad_norm": 1.1651684045791626,
      "learning_rate": 8.049189491335943e-06,
      "loss": 0.1973,
      "step": 3400
    },
    {
      "epoch": 3.11,
      "grad_norm": 4.732381343841553,
      "learning_rate": 7.909446618222472e-06,
      "loss": 0.166,
      "step": 3410
    },
    {
      "epoch": 3.11,
      "grad_norm": 7.517033100128174,
      "learning_rate": 7.769703745109e-06,
      "loss": 0.1096,
      "step": 3420
    },
    {
      "epoch": 3.11,
      "grad_norm": 19.878673553466797,
      "learning_rate": 7.629960871995529e-06,
      "loss": 0.2055,
      "step": 3430
    },
    {
      "epoch": 3.11,
      "grad_norm": 2.070005178451538,
      "learning_rate": 7.490217998882057e-06,
      "loss": 0.208,
      "step": 3440
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.1317098140716553,
      "learning_rate": 7.3504751257685855e-06,
      "loss": 0.1052,
      "step": 3450
    },
    {
      "epoch": 3.12,
      "grad_norm": 5.311214923858643,
      "learning_rate": 7.2107322526551156e-06,
      "loss": 0.2083,
      "step": 3460
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.5385725498199463,
      "learning_rate": 7.070989379541644e-06,
      "loss": 0.1331,
      "step": 3470
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.7508240938186646,
      "learning_rate": 6.931246506428172e-06,
      "loss": 0.2324,
      "step": 3480
    },
    {
      "epoch": 3.13,
      "grad_norm": 17.915359497070312,
      "learning_rate": 6.791503633314701e-06,
      "loss": 0.2603,
      "step": 3490
    },
    {
      "epoch": 3.13,
      "grad_norm": 7.94109582901001,
      "learning_rate": 6.65176076020123e-06,
      "loss": 0.1977,
      "step": 3500
    },
    {
      "epoch": 3.13,
      "grad_norm": 3.8253936767578125,
      "learning_rate": 6.512017887087758e-06,
      "loss": 0.1944,
      "step": 3510
    },
    {
      "epoch": 3.13,
      "grad_norm": 3.596938133239746,
      "learning_rate": 6.3722750139742885e-06,
      "loss": 0.1845,
      "step": 3520
    },
    {
      "epoch": 3.14,
      "grad_norm": 5.320721626281738,
      "learning_rate": 6.232532140860817e-06,
      "loss": 0.1367,
      "step": 3530
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.7267037630081177,
      "learning_rate": 6.092789267747345e-06,
      "loss": 0.2554,
      "step": 3540
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.4472544193267822,
      "learning_rate": 5.953046394633874e-06,
      "loss": 0.1438,
      "step": 3550
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.8530330657958984,
      "learning_rate": 5.813303521520403e-06,
      "loss": 0.1094,
      "step": 3560
    },
    {
      "epoch": 3.15,
      "grad_norm": 3.6720876693725586,
      "learning_rate": 5.673560648406931e-06,
      "loss": 0.0924,
      "step": 3570
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.8920308947563171,
      "learning_rate": 5.5338177752934606e-06,
      "loss": 0.242,
      "step": 3580
    },
    {
      "epoch": 3.15,
      "grad_norm": 7.965010166168213,
      "learning_rate": 5.39407490217999e-06,
      "loss": 0.1533,
      "step": 3590
    },
    {
      "epoch": 3.15,
      "grad_norm": 9.660565376281738,
      "learning_rate": 5.254332029066518e-06,
      "loss": 0.1563,
      "step": 3600
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.2042454481124878,
      "learning_rate": 5.114589155953047e-06,
      "loss": 0.124,
      "step": 3610
    },
    {
      "epoch": 3.16,
      "grad_norm": 6.618047714233398,
      "learning_rate": 4.974846282839576e-06,
      "loss": 0.205,
      "step": 3620
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.298235297203064,
      "learning_rate": 4.835103409726104e-06,
      "loss": 0.0688,
      "step": 3630
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.3493913412094116,
      "learning_rate": 4.695360536612633e-06,
      "loss": 0.1225,
      "step": 3640
    },
    {
      "epoch": 3.17,
      "grad_norm": 9.10888957977295,
      "learning_rate": 4.555617663499162e-06,
      "loss": 0.114,
      "step": 3650
    },
    {
      "epoch": 3.17,
      "grad_norm": 4.474492073059082,
      "learning_rate": 4.41587479038569e-06,
      "loss": 0.1612,
      "step": 3660
    },
    {
      "epoch": 3.17,
      "grad_norm": 3.429523229598999,
      "learning_rate": 4.2761319172722195e-06,
      "loss": 0.1689,
      "step": 3670
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.6094630360603333,
      "learning_rate": 4.136389044158749e-06,
      "loss": 0.1098,
      "step": 3680
    },
    {
      "epoch": 3.18,
      "grad_norm": 1.1854068040847778,
      "learning_rate": 3.996646171045277e-06,
      "loss": 0.2087,
      "step": 3690
    },
    {
      "epoch": 3.18,
      "grad_norm": 9.205829620361328,
      "learning_rate": 3.8569032979318056e-06,
      "loss": 0.2169,
      "step": 3700
    },
    {
      "epoch": 3.18,
      "grad_norm": 9.120864868164062,
      "learning_rate": 3.717160424818335e-06,
      "loss": 0.1852,
      "step": 3710
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.9524430632591248,
      "learning_rate": 3.577417551704863e-06,
      "loss": 0.2998,
      "step": 3720
    },
    {
      "epoch": 3.19,
      "grad_norm": 4.146412372589111,
      "learning_rate": 3.437674678591392e-06,
      "loss": 0.1988,
      "step": 3730
    },
    {
      "epoch": 3.19,
      "grad_norm": 2.381260871887207,
      "learning_rate": 3.2979318054779213e-06,
      "loss": 0.105,
      "step": 3740
    },
    {
      "epoch": 3.19,
      "grad_norm": 21.648094177246094,
      "learning_rate": 3.1581889323644497e-06,
      "loss": 0.1516,
      "step": 3750
    },
    {
      "epoch": 3.19,
      "grad_norm": 15.104497909545898,
      "learning_rate": 3.018446059250978e-06,
      "loss": 0.1608,
      "step": 3760
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.7533896565437317,
      "learning_rate": 2.8787031861375073e-06,
      "loss": 0.1517,
      "step": 3770
    },
    {
      "epoch": 3.2,
      "grad_norm": 10.656826972961426,
      "learning_rate": 2.738960313024036e-06,
      "loss": 0.1135,
      "step": 3780
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.6693223118782043,
      "learning_rate": 2.5992174399105645e-06,
      "loss": 0.1332,
      "step": 3790
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.5746699571609497,
      "learning_rate": 2.4594745667970933e-06,
      "loss": 0.1732,
      "step": 3800
    },
    {
      "epoch": 3.21,
      "grad_norm": 12.753913879394531,
      "learning_rate": 2.319731693683622e-06,
      "loss": 0.1464,
      "step": 3810
    },
    {
      "epoch": 3.21,
      "grad_norm": 11.099847793579102,
      "learning_rate": 2.179988820570151e-06,
      "loss": 0.0981,
      "step": 3820
    },
    {
      "epoch": 3.21,
      "grad_norm": 3.246058702468872,
      "learning_rate": 2.04024594745668e-06,
      "loss": 0.1882,
      "step": 3830
    },
    {
      "epoch": 3.22,
      "grad_norm": 3.856889247894287,
      "learning_rate": 1.9005030743432086e-06,
      "loss": 0.2398,
      "step": 3840
    },
    {
      "epoch": 3.22,
      "grad_norm": 7.585298538208008,
      "learning_rate": 1.7607602012297372e-06,
      "loss": 0.1289,
      "step": 3850
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.4175045490264893,
      "learning_rate": 1.621017328116266e-06,
      "loss": 0.2374,
      "step": 3860
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.4472607374191284,
      "learning_rate": 1.4812744550027949e-06,
      "loss": 0.09,
      "step": 3870
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.8075383901596069,
      "learning_rate": 1.3415315818893237e-06,
      "loss": 0.1072,
      "step": 3880
    },
    {
      "epoch": 3.23,
      "grad_norm": 16.49795913696289,
      "learning_rate": 1.2017887087758525e-06,
      "loss": 0.1787,
      "step": 3890
    },
    {
      "epoch": 3.23,
      "grad_norm": 13.092514038085938,
      "learning_rate": 1.0620458356623811e-06,
      "loss": 0.1517,
      "step": 3900
    },
    {
      "epoch": 3.23,
      "grad_norm": 18.978477478027344,
      "learning_rate": 9.223029625489101e-07,
      "loss": 0.132,
      "step": 3910
    },
    {
      "epoch": 3.24,
      "grad_norm": 9.010387420654297,
      "learning_rate": 7.825600894354388e-07,
      "loss": 0.2474,
      "step": 3920
    },
    {
      "epoch": 3.24,
      "grad_norm": 6.510222434997559,
      "learning_rate": 6.428172163219676e-07,
      "loss": 0.0966,
      "step": 3930
    },
    {
      "epoch": 3.24,
      "grad_norm": 5.77733850479126,
      "learning_rate": 5.030743432084964e-07,
      "loss": 0.2579,
      "step": 3940
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.7094335556030273,
      "learning_rate": 3.633314700950252e-07,
      "loss": 0.0885,
      "step": 3950
    },
    {
      "epoch": 3.25,
      "grad_norm": 7.817173957824707,
      "learning_rate": 2.2358859698155395e-07,
      "loss": 0.0911,
      "step": 3960
    },
    {
      "epoch": 3.25,
      "grad_norm": 2.380784273147583,
      "learning_rate": 8.384572386808273e-08,
      "loss": 0.1991,
      "step": 3970
    },
    {
      "epoch": 3.25,
      "eval_accuracy": 0.9307165437302424,
      "eval_loss": 0.28819116950035095,
      "eval_runtime": 576.1858,
      "eval_samples_per_second": 13.176,
      "eval_steps_per_second": 1.647,
      "step": 3976
    },
    {
      "epoch": 3.25,
      "step": 3976,
      "total_flos": 3.965859140190113e+19,
      "train_loss": 1.3087514718053805,
      "train_runtime": 7045.3307,
      "train_samples_per_second": 4.515,
      "train_steps_per_second": 0.564
    },
    {
      "epoch": 3.25,
      "eval_accuracy": 0.9261370834917015,
      "eval_loss": 0.3000016510486603,
      "eval_runtime": 601.28,
      "eval_samples_per_second": 13.127,
      "eval_steps_per_second": 1.641,
      "step": 3976
    },
    {
      "epoch": 3.25,
      "eval_accuracy": 0.9261370834917015,
      "eval_loss": 0.3000016510486603,
      "eval_runtime": 589.4489,
      "eval_samples_per_second": 13.39,
      "eval_steps_per_second": 1.674,
      "step": 3976
    }
  ],
  "logging_steps": 10,
  "max_steps": 3976,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 500,
  "total_flos": 3.965859140190113e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
